import streamlit as st
from together import Together

# Together AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = Together(api_key=st.secrets["TOGETHER_API_KEY"])

# í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
st.set_page_config(
    page_title="Llama 3.3 70B Chatbot",
    page_icon="ğŸ¦™",
    layout="wide"
)

# ì œëª©ê³¼ ì„¤ëª… ì¶”ê°€
st.title("Llama 3.3 70B Chatbot")
st.markdown("Together AIì˜ Llama 3.3 70B ëª¨ë¸ì„ ì‚¬ìš©í•œ ëŒ€í™” í…ŒìŠ¤íŠ¸ìš© ë°ëª¨ì…ë‹ˆë‹¤.")

# ì±—ë´‡ ì‘ë‹µ ìƒì„± í•¨ìˆ˜
def generate_response(messages):
    try:
        response = client.chat.completions.create(
            model="meta-llama/Llama-3.3-70B-Instruct-Turbo-Free",
            messages=messages,
            temperature=0.7,
            top_p=0.7,
            top_k=50,
            repetition_penalty=1,
            stop=["<|eot_id|>", "<|eom_id|>"]
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"ì£„ì†¡í•©ë‹ˆë‹¤, ì‘ë‹µ ìƒì„± ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# ì˜ˆì‹œ ë©”ì‹œì§€ ë²„íŠ¼ë“¤
example_messages = ["ì•ˆë…•í•˜ì„¸ìš”!", "ë„ˆëŠ” ëˆ„êµ¬ë‹ˆ?", "ë¬´ì—‡ì„ í•  ìˆ˜ ìˆë‹ˆ?"]
cols = st.columns(len(example_messages))
for col, example in zip(cols, example_messages):
    if col.button(example):
        st.session_state.messages.append({"role": "user", "content": example})
        with st.spinner("ìƒê° ì¤‘..."):
            chat_messages = [{"role": m["role"], "content": m["content"]} for m in st.session_state.messages]
            response = generate_response(chat_messages)
            st.session_state.messages.append({"role": "assistant", "content": response})

# ì´ì „ ëŒ€í™” ë‚´ìš© í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    with st.chat_message("assistant"):
        with st.spinner("ìƒê° ì¤‘..."):
            chat_messages = [{"role": m["role"], "content": m["content"]} for m in st.session_state.messages]
            response = generate_response(chat_messages)
            st.markdown(response)
            st.session_state.messages.append({"role": "assistant", "content": response}) 